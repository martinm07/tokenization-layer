{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note, when viewing this file on GitHub, the MathJax (and other things) can be a little wonky /:**<br>\n",
    "**For better formatting, I suggest you read this file on Deepnote:**<br>\n",
    "<b><a href=\"https://deepnote.com/viewer/github/martinm07/tokenization-layer/blob/main/concept-explained.ipynb\">Read this file on Deepnote</a></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00002-3a7a0aec-1bc4-4f78-a247-f711bf427c73",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7207,
    "execution_start": 1627764030679,
    "is_code_hidden": false,
    "source_hash": "8b4f18bf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.5.0\n"
     ]
    }
   ],
   "source": [
    "# General libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# ML & DL libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Misc libraries\n",
    "import textwrap\n",
    "import re\n",
    "import string\n",
    "from copy import copy\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "from colorama import Fore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00001-9a2773d5-8307-4d61-a735-2902b470589d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1627765566923,
    "is_code_hidden": true,
    "source_hash": "56502f36",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class color:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-bbfe47f6-ab84-4a69-8b8c-90be93270c41",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-bd4c6796-e88b-4eeb-8965-3d0ccff62e7d",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "*Tokenization* is the first basic step in almost any natural language processing pipeline. Tokenization is the process of splitting up text into smaller chunks. We do this because for someone or something to see a brand new text (for example a book) and \"read\" it, they need to link it to stuff they've seen before and know the meaning of (e.g. words or phrases). Then, they build up the meaning of the text from there, *inferring* the meaning using the rules of natural language.<br>\n",
    "This \"*stuff they've seen before*\" is *tokens*. Tokens (for an algorithm) make up the building blocks of natural language. It's what they use to construct the meaning of any text, using the rules of natural language (which they have to learn).<br>\n",
    "So, as you can probably guess, tokenization is a vital part of the pipeline, and in this notebook, we will attempt a new kind of tokenization, training the tokenization algorithm like a layer in the neural network we want to have one for. Let's dive in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-36f11b4b-f43b-499d-b7fd-7168e09f293e",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "The process of tokenization is *splitting up the text*, however we can think of it as \"finding tokens in the text\" too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00002-e2c0d055-3c48-482b-a83f-93df7ab99416",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1627764049672,
    "source_hash": "b5437f6e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_text = 'Hello and welcome to this exquisite passage of text who\\'s solemn purpose is to act in place of a real piece of text, what is known as an \"example\".'\n",
    "tokens = [\"and\", \"to\", \"this\", \"is\", \"in\", \"of\", \"a\", \"as\", \"an\", \"place\", \"passage\", \"text\", \n",
    "          \"example\", \"known\", \"welcome\", \"purpose\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00004-5d922cd0-44ab-472c-b990-c96c40950eca",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1627764050260,
    "source_hash": "12ed5faf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenizer(tokens, text):\n",
    "    tokens_sorted = list(pd.Series([len(token) for token in tokens], index=tokens).sort_values(ascending=False).keys())\n",
    "    out = pd.Series(dtype=\"object\")\n",
    "    for token in tokens_sorted:\n",
    "        token_inds = [m.start() for m in re.finditer(re.escape(token), text)]\n",
    "        out = pd.concat([out, pd.Series(token, index=token_inds)])\n",
    "        text = text.replace(token, \" \".join([\"\" for _ in range(len(token)+1)]))\n",
    "    return list(out.sort_index().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00008-a8aa9dae-7024-43c4-aac4-4df938075d9f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 24,
    "execution_start": 1627764051121,
    "source_hash": "ac4ce4cc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_text_tokenized = tokenizer(tokens, example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00005-20f648db-1cd3-42d1-b4f3-f44010cc76c4",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 22,
    "execution_start": 1627764051554,
    "is_code_hidden": true,
    "source_hash": "40f971ea",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mTokenizes the text\u001b[39m\n",
      "Hello and welcome to this exquisite passage of text who's solemn purpose is to act in place of a real piece of text,\n",
      "what is known as an \"example\".\n",
      "\u001b[34minto:\u001b[39m\n",
      "['and', 'welcome', 'to', 'this', 'is', 'passage', 'of', 'text', 'purpose', 'is', 'to', 'a', 'in', 'place', 'of', 'a',\n",
      "'a', 'of', 'text', 'a', 'is', 'known', 'as', 'an', 'example']\n",
      "\u001b[34mUsing the tokens:\u001b[39m\n",
      "['and', 'to', 'this', 'is', 'in', 'of', 'a', 'as', 'an', 'place', 'passage', 'text', 'example', 'known', 'welcome',\n",
      "'purpose']\n"
     ]
    }
   ],
   "source": [
    "print(Fore.BLUE+\"Tokenizes the text\"+Fore.RESET)\n",
    "for line in textwrap.wrap(example_text, width=118):\n",
    "    print(line)\n",
    "print(Fore.BLUE+\"into:\"+Fore.RESET)\n",
    "for line in textwrap.wrap(str(example_text_tokenized), width=118):\n",
    "    print(line)\n",
    "print(Fore.BLUE+\"Using the tokens:\"+Fore.RESET)\n",
    "for line in textwrap.wrap(str(tokens), width=118):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-a3072e32-8aef-41fd-af8e-be35a608ab66",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "This is an easier way of thinking about it when dealing with more complex tokenization (i.e. more than \"split by the whitespace\").<br>\n",
    "Now, this is like a function, which, using a list of tokens, can take in some text and tokenize it using the tokens. To do that we just need a list of tokens to use. Actually getting such a list is the meat of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-013ab1df-0140-4987-8e2e-52bc56b50219",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "One possible way of doing this is to try optimize a list of (intially random) tokens. To do this we could actually make a \"tokenization layer\", that goes at the frony of a neural network trying to solve some NLP task (and subsequently needs tokens). Then, the list of tokens trains along with the rest of the network. Let's define this layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00009-23d968d5-6e11-448e-806f-6414c25fb600",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Defining the Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-6dcebfd5-d6ad-41d8-a6a2-9b3baf760724",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "The tokenization neuron is made up of a pattern, and a signature (named \"out\"). When it takes in an input, it looks for matches of the pattern in the input, and then returns it's signature, \"out\", at these matches, with $0$ everywhere else to make it the same length as the input.<br>\n",
    "The input of this neuron would be one-hot encoded, having the shape `(num_categories, sequence_len)`. Typically, the input would be the text input of the neural network you're trying to train, and it would be one-hot encoded as characters, so `num_categories` is the number of different characters in the text. The neuron's pattern is then also the same scheme, having shape `(num_categories, pattern_len)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00011-e72a0c13-3a19-4644-8ac1-e9fac296d0ea",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Let's look at an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00012-28c2bfdd-2a8a-40f8-ba81-91f903e0cc63",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Firstly, we have our text data we want to feed our neuron:\n",
    "$$\n",
    "\\text{text = \"a bad cab\"}\n",
    "$$\n",
    "We need to one-hot encode it first:\n",
    "$$\n",
    "\\text{\"a\"}=\n",
    "\\begin{bmatrix} \n",
    "1 \\\\ \n",
    "0 \\\\ \n",
    "0 \\\\ \n",
    "0 \\\\ \n",
    "0 \n",
    "\\end{bmatrix} \n",
    "\\text{, \"b\"}=\n",
    "\\begin{bmatrix} \n",
    "0 \\\\ \n",
    "1 \\\\ \n",
    "0 \\\\ \n",
    "0 \\\\ \n",
    "0 \n",
    "\\end{bmatrix} \n",
    "\\text{, \"c\"}=\n",
    "\\begin{bmatrix} \n",
    "0 \\\\ \n",
    "0 \\\\ \n",
    "1 \\\\ \n",
    "0 \\\\ \n",
    "0 \n",
    "\\end{bmatrix} \n",
    "\\text{, \"d\"}=\n",
    "\\begin{bmatrix} \n",
    "0 \\\\ \n",
    "0 \\\\ \n",
    "0 \\\\ \n",
    "1 \\\\ \n",
    "0 \n",
    "\\end{bmatrix} \n",
    "\\text{, \" \"}=\n",
    "\\begin{bmatrix} \n",
    "0 \\\\ \n",
    "0 \\\\ \n",
    "0 \\\\ \n",
    "0 \\\\ \n",
    "1 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{text}=\\begin{bmatrix} 1&0&0&1&0&0&0&1&0 \\\\ 0&0&1&0&0&0&0&0&1 \\\\ 0&0&0&0&0&0&1&0&0 \\\\ 0&0&0&0&1&0&0&0&0 \\\\ 0&1&0&0&0&1&0&0&0 \\end{bmatrix}\n",
    "$$\n",
    "Now, let's say our neuron's pattern and signature (\"out\") is:\n",
    "$$\n",
    "\\text{pattern} = \\begin{bmatrix} 0&1&0 \\\\ 1&0&0 \\\\ 0&0&0 \\\\ 0&0&1 \\\\ 0&0&0 \\end{bmatrix} \n",
    "\\text{, out} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix}\n",
    "$$\n",
    "When our neuron gets the text input it returns:\n",
    "$$\n",
    "f(text, pattern, out) = \\text{return  }\n",
    "text\n",
    "\\text{  of 0s except with  }\n",
    "out\n",
    "\\text{  where  }\n",
    "pattern\n",
    "\\text{  in  }\n",
    "text\n",
    "$$\n",
    "\n",
    "$$\n",
    "f(\\text{text}, \\text{pattern}, \\text{out}) = \\begin{bmatrix} 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-7381d2a6-586b-4503-a9b6-08ee89ca6778",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Defining the Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00014-0a280068-007b-4b5c-b339-67b7a7d6e1de",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Now, this is one neuron, how do we make a tokenization \"layer\"? Well, our layer is made up of a stack of neurons, each neuron has it's own $\\text{pattern}$ and $\\text{out}$, and all take in the same input. All the neurons individually output their own \"version\" of the text, all only keeping what the pattern recognized, signified by that neuron's $\\text{out}$, which will follow the same scheme as the input, having the shape `(num_neurons, 1)`, with $1$ at one index and $0$ at every other. This is so that, when getting the output of the layer itself, we can just add up (element-wise) the outputs of all the neurons.<br>\n",
    "Here's an example of what this layer would look like in practice (note that $f_n$ is the $n$th neuron, $p_n$ is the $n$th pattern, $o_n$ is the $n$th out and $t$ is the input text):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f_1(t, p_1, o_1) = \\begin{bmatrix} 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\end{bmatrix}\n",
    ", f_2(t, p_2, o_2) = \\begin{bmatrix} 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\end{bmatrix}\n",
    ", f_3(t, p_3, o_3) = \\begin{bmatrix} 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    ", f_4(t, p_4, o_4) = \\begin{bmatrix} 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 1 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\end{bmatrix}\n",
    ", f_5(t, p_5, o_5) =  \\begin{bmatrix} 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00015-61e49b22-affb-4779-b6b1-d319224afb5f",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "$$\n",
    "\\text{layer output} = f_1(t, p_1, o_1) + f_2(t, p_2, o_2) + f_3(t, p_3, o_3) + f_4(t, p_4, o_4) + f_5(t, p_5, o_5) = \n",
    "\\begin{bmatrix}0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 1 \\\\ 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00016-4780907e-ed9f-48f4-bc94-0b652ad249ae",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "You can imagine how this would work for a tokenization algorithm; the patterns are like tokens, and the layer output is a representation of the text with said tokens.<br>\n",
    "Now, while this is all well and good, we still need something if we want to *train* this; and that's the derivatives.<br>\n",
    "Neural networks are trained through a process called *gradient descent*, I won't go into the intuition but this requires the derivatives at different parts of the neural network. That means, to train this layer, we need to know it's *derivative*, which, is hard to do as it's not well mathematically defined. Luckily, we can mathematically define it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00017-97b76038-a0c0-4cb9-9a13-7602ee8a3030",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Finding the Derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00018-2eb33b95-0106-4477-a82c-09eb318a226b",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "This neuron is actually pretty similar to *convolutions* (from CNNs), and we can redefine our neuron to use them here.<br>\n",
    "Here's what the convolution operation actually is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix}\n",
    "x_{11} & x_{12} & x_{13} \\\\\n",
    "x_{21} & x_{22} & x_{23} \\\\\n",
    "x_{31} & x_{32} & x_{33} \\\\\n",
    "\\end{bmatrix} * \n",
    "\\begin{bmatrix}\n",
    "f_{11} & f_{12} \\\\\n",
    "f_{21} & f_{22} \n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "o_{11} & o_{12} \\\\\n",
    "o_{21} & o_{22} \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$o_{11} = f_{11}x_{11}+f_{12}x_{12}+f_{21}x_{21}+f_{22}x_{22}$$ $$o_{12} = f_{11}x_{12}+f_{12}x_{13}+f_{21}x_{22}+f_{22}x_{23}$$ $$o_{21} = f_{11}x_{21}+f_{12}x_{22}+f_{21}x_{31}+f_{22}x_{32}$$ $$o_{22} = f_{11}x_{22}+f_{12}x_{23}+f_{21}x_{32}+f_{22}x_{33}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00020-b04e917e-afa2-4ac8-b3f7-d6d930a7ecc6",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<img style=\"width: 60%; margin-left: 20%;\" src=\"https://miro.medium.com/max/1050/1*K7dINARev0NUB-HWp9mbwA.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00025-2bb34401-cf59-46f3-b72d-8a2df1e0fff3",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<p style=\"text-align: center;\"><i>Credit for GIF goes to (as far as I can tell) <a href=\"https://medium.com/@pavisj\">Pavithra Solai</a>, who also<br>has a <a href=\"https://medium.com/@pavisj/convolutions-and-backpropagations-46026a8f5d2c\">great article</a> for those getting started with convolutions.</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00021-138a66d5-c08c-4392-89d0-7fd4524fcddb",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "As you can see, we simply \"slide\" the filter over the input, multiplying the values element-wise and adding them up at each step.<br>\n",
    "If we say our pattern is the filter $F$, and the input text is $X$, we get something similar to what we defined our neuron to be before. Let us see with an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00022-dac440aa-3ba4-4bfa-9ceb-7a5bfe5b85cf",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "$$\n",
    "\\begin{bmatrix}\n",
    "1&0&0&1&0&0&0&1&0 \\\\\n",
    "0&0&1&0&0&0&0&0&1 \\\\\n",
    "0&0&0&0&0&0&1&0&0 \\\\\n",
    "0&0&0&0&1&0&0&0&0 \\\\\n",
    "0&1&0&0&0&1&0&0&0\n",
    "\\end{bmatrix} * \\begin{bmatrix}\n",
    "0&1&0 \\\\\n",
    "1&0&0 \\\\\n",
    "0&0&0 \\\\\n",
    "0&0&1 \\\\\n",
    "0&0&0\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "0 & 0 & 3 & 0 & 0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00023-1bfe6f74-ae68-42da-9994-e66345a1a821",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Remebering what the output of this neuron should be, this is pretty close! Where the $3$ is here is where the neuron found a full match with the pattern (because all *three* letters in the pattern matched). So, we could re-define our neuron to be this:\n",
    "$$\n",
    "f(text, pattern, out) = \\frac{text * pattern}{len(pattern)} \\text{ with }out\\text{ where }== 1\n",
    "$$\n",
    "However, a lot of it is redundant (as we won't be changing $out$), so all we really have to optimize (i.e. get the derivative) for is:\n",
    "\n",
    "$$\n",
    "\\frac{text * pattern}{len(pattern)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00024-82dc796f-ddd2-4b45-911d-c4242256a4d5",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "You could see how optimizing $pattern$ in this version of the neuron would result in similar optimization in the actual version of forward propagation that we'll be using.<br>\n",
    "I won't go into the details of deriving the convolution (there's other places for that), so here would be the derivatives with respect to $pattern$ and $text$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial C}{\\partial pattern} = \\frac{\\partial C}{\\partial f} \\cdot \\frac{\\partial f}{\\partial pattern} = \\frac{\\partial C}{\\partial f} \\cdot \\frac{\\partial}{\\partial P}[\\frac{text * pattern}{len(pattern)}]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    " = \\frac{text * \\frac{\\partial C}{\\partial f}}{len(pattern)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "$$\n",
    "\\frac{\\partial C}{\\partial text} = \\frac{\\partial C}{\\partial f} \\cdot \\frac{\\partial f}{\\partial text} = \\frac{\\partial C}{\\partial f} \\cdot \\frac{\\partial}{\\partial text}[\\frac{text * pattern}{len(pattern)}]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00025-226a8f70-95db-4d07-84fb-b4ea38433e8b",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "$$\n",
    " = \\frac{pad(\\frac{\\partial C}{\\partial f}) * rot180(pattern)}{len(pattern)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00026-485b545f-f68a-4b49-9216-849e3f4ff9bd",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Here, we're getting the derivative of the (theoretical) cost $C$ with respect to $pattern$ and $text$. By way of the chain rule, this is the same as $\\frac{\\partial C}{\\partial f} \\cdot \\frac{\\partial f}{\\partial \\text{parameter}}$, and from there we can get the derivatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00028-b26a8e30-9179-427f-8eee-b8ae2bafb1fa",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# The Finer Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00028-49e989db-396c-44c5-8a8f-a3334e22364b",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "There are some problems with what we've discussed so far.<br>\n",
    "For one thing; *changing $pattern$*; we want to change $pattern$ as to minimize the cost (using gradient descent), however, gradient descent *expects* $pattern$ to be continuous (as in, it could be any real number), but $pattern$ is meant to be a one-hot encoding like the text! We can solve this by saying that what gradient descent is trying to optimize *is* continuous, let's call it $p_{\\text{intermediate}}$, and we derive $pattern$ from $p_{\\text{intermediate}}$ by saying that, for every column, the highest value is where there'll be the $1$, and everything else is $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00027-d30b5ba8-145f-4c97-89d3-7a1d1d29979a",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "$$\n",
    "p_{\\text{intermediate}} = \\begin{bmatrix}\n",
    "0.93 & 0.18 & 0.38 \\\\\n",
    "0.49 & 0.79 & 0.80 \\\\\n",
    "0.76 & 0.85 & 0.13 \\\\\n",
    "0.82 & 0.65 & 0.16 \\\\\n",
    "0.83 & 0.42 & 0.08\n",
    "\\end{bmatrix} \\longmapsto p = \\begin{bmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 0 & 1 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00031-d7312eb8-c776-4221-8f94-6fcc9c53fbcf",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Additionally, we would also like the pattern to *not* contain characters in some places (i.e. columns of just $0$s). To do this, we can add an extra rule saying that \"if the sum of all the values in a column is less than (or equal to) $0$, then that column will not contain a character and just be $0$s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00032-d1367e13-71da-43c5-ac2c-c4eac82c30de",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "However, this creates another problem; it's now very easy for gradient descent to make no-character characters in tokens, perhaps *too* easy. We would like to control just how easy it is to make no-character characters, and to do that, we can simply multiply the gradient $\\partial C / \\partial P$ by $\\sigma (P)$, where"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00033-ffa06288-83ef-494d-920f-e049d842588d",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "$$\n",
    "\\sigma(x) = \\begin{cases}\n",
    "0 & x \\leq 0 \\\\\n",
    "\\frac{x^{\\left(-\\beta -1\\right)}}{\\left(1+x^{-\\beta}\\left(1-x\\right)^{\\beta}\\right)^{2}\\left(-x+1\\right)^{\\left(-\\beta +1\\right)}} & 0 < x < 1 \\\\\n",
    "0 & x \\geq 1 \\\\\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00034-8a6fdd10-8a05-4d86-b932-92c72e6bcdfd",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "This is the graph of the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00035-c60ee739-1d02-4846-b216-a6fa6cb2b100",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 552,
    "execution_start": 1627755195102,
    "is_code_hidden": true,
    "source_hash": "513165fd",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigma(x, b=3.0):\n",
    "    if x <= 0:\n",
    "        return 0.\n",
    "    elif x >= 1:\n",
    "        return 0.\n",
    "    else:\n",
    "        return (x**(-b-1)) / ((1 + x**(-b) * (1 - x)**b)**2 * (-x + 1)**(-b+1))\n",
    "\n",
    "vals = [sigma(x) for x in np.arange(-0.5, 1.5, 0.01)]\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.title(r\"$\\sigma (x)$ where $\\beta = 3.0$\", fontdict={\"fontsize\":15})\n",
    "plt.plot(np.arange(-0.5, 1.5, 0.01), vals);\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00036-83a9e496-75d9-43f4-a5c4-631fb726c918",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "With this, when a value $p \\in P$ approaches the two values it actually *can* be (i.e. $0$ or $1$), the gradient shrinks, slowing down updates and keeping $p$ within the range $(0,1)$. However we would like *some* negative values, and to do that we can add another controllable parameter $\\alpha$, where the range of $p$ is then $(\\alpha, 1)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00037-80d3fbe9-97f5-49ab-a2fa-bed02600d522",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 329,
    "execution_start": 1627755956842,
    "is_code_hidden": true,
    "source_hash": "7ba6ee8e",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def bump_func_leaky(x, a=-0.2, b=3.0):\n",
    "    a = -a/(-a+1)\n",
    "    if x <= (-1/(1-a) + 1):\n",
    "        return 0.\n",
    "    elif x >= 1:\n",
    "        return 0.\n",
    "    else:\n",
    "        x = (1-a)*x + a\n",
    "        return (x**(-b-1)) / ((1 + x**(-b) * (1 - x)**b)**2 * (-x + 1)**(-b+1))\n",
    "\n",
    "vals = [bump_func_leaky(x) for x in np.arange(-0.5, 1.5, 0.01)]\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.title(r\"$\\sigma (x)$ where $\\beta = 3.0$ and $\\alpha = -0.2$\", fontdict={\"fontsize\":15})\n",
    "plt.plot(np.arange(-0.5, 1.5, 0.01), vals);\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00028-26896209-e6e2-41d4-a50d-892dad35e0a0",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Okay, let's start doing some code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00029-f6646d07-4906-4b1e-904c-fe5d568851d2",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Coding it Out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00030-38bcc5a3-cb37-469f-82a5-a2eb210b501f",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "First thing's first, we need a natural language processing task that we would need tokenization for. Here, I pick the [IMDB Movie Reviews](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews) dataset (very *exotic*, I know), where we must predict if reviews were positive or negative towards the movie. Let's get the data and do some basic preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00029-d2f9cb44-bfa8-47d2-9b27-763663ed09a4",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 25534,
    "execution_start": 1627764066873,
    "source_hash": "86e97e33",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  why did i waste my time with this movie there ...       0.0\n",
      "1  in the middle of the hole i emailed a friend o...       1.0\n",
      "2  the preposterous premise of this flick has to ...       0.0\n",
      "3  quite possibly the nicest woman in show busine...       0.0\n",
      "4  probably the only thing that got the movie up ...       0.0\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "data = data.sample(len(data)).reset_index(drop=True)\n",
    "\n",
    "# Strip \"<br />\" tags and convert to lowercase\n",
    "data[\"review\"] = data[\"review\"].apply(lambda x: x.replace(\"<br />\", \" \").lower())\n",
    "# Strip punctuation\n",
    "data[\"review\"] = data[\"review\"].apply(lambda x: re.sub(f\"[{string.punctuation}]\", \"\", x))\n",
    "# Get top 30 most common characters\n",
    "chars = \"\".join(pd.Series(list(\" \".join(data[\"review\"].to_list()))).value_counts().keys()[:30])\n",
    "# Remove everything except the top 30 most common characters\n",
    "data[\"review\"] = data[\"review\"].apply(lambda x: re.sub(f\"[^{chars}]\", \"\", x))\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "data[[\"sentiment\"]] = OrdinalEncoder().fit_transform(data[[\"sentiment\"]])\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00032-8770fd69-5505-42b8-8c64-1c55327368c8",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Now, let's split it into a train, test and validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "00032-a8ecaaeb-37d3-4968-b649-7191fca8246a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7,
    "execution_start": 1627764092403,
    "source_hash": "746a4dbc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "00034-b124aedc-3063-4b41-a39c-477f35cef2c4",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 48,
    "execution_start": 1627764092416,
    "source_hash": "bd54af24",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data[\"review\"], data[\"sentiment\"], test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00035-06b4c6f7-2f03-42fa-8124-2d1724eecf7c",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Finally, let's convert these to TensorFlow datasets and do the final preprocessing (i.e. one-hot encoding the characters and padding them to be the same length), as well as batching it to length 32:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "00035-cbc95153-41b1-4b84-a42f-3ee8c7933e14",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2213,
    "execution_start": 1627764092478,
    "source_hash": "8e5bc0f8",
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\marti\\anaconda3\\envs\\pythongeneral\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "(<tf.Tensor: shape=(30, 2000), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 1., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>)\n",
      "(<tf.Tensor: shape=(30, 2000), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>)\n",
      "(<tf.Tensor: shape=(30, 2000), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 1., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "# Encode characters into integers\n",
    "def ordinal_encode(x):\n",
    "    split = tf.strings.bytes_split(x)\n",
    "    chars_tensor = tf.constant(list(chars))\n",
    "    return tf.argmax(tf.map_fn(lambda x: chars_tensor==x, split, dtype=tf.bool), axis=1)\n",
    "\n",
    "# One-hot encode integers\n",
    "def onehot(x):\n",
    "    return tf.transpose(tf.one_hot(x, depth=len(chars)))\n",
    "\n",
    "# Clip and pad all reviews to be 2000 characters long\n",
    "def clip_and_pad(x):\n",
    "    output_length = 2000\n",
    "    shape = tf.shape(x)\n",
    "    if shape[1] >= output_length:\n",
    "        return x[:, :output_length]\n",
    "    else:\n",
    "        return tf.concat([x, tf.zeros((shape[0], output_length-shape[1]))], axis=1)\n",
    "\n",
    "X_train, X_val, X_test = tf.data.Dataset.from_tensor_slices(X_train), tf.data.Dataset.from_tensor_slices(X_val), tf.data.Dataset.from_tensor_slices(X_test)\n",
    "X_train, X_val, X_test = X_train.map(ordinal_encode).map(onehot).map(clip_and_pad), X_val.map(ordinal_encode).map(onehot).map(clip_and_pad), X_test.map(ordinal_encode).map(onehot).map(clip_and_pad)\n",
    "\n",
    "y_train, y_val, y_test = tf.data.Dataset.from_tensor_slices(np.asarray(y_train).astype('float32')), tf.data.Dataset.from_tensor_slices(np.asarray(y_val).astype('float32')), tf.data.Dataset.from_tensor_slices(np.asarray(y_test).astype('float32'))\n",
    "\n",
    "train_set, val_set, test_set = tf.data.Dataset.zip((X_train, y_train)), tf.data.Dataset.zip((X_val, y_val)), tf.data.Dataset.zip((X_test, y_test))\n",
    "for item in train_set.take(3):\n",
    "    print(item)\n",
    "\n",
    "train_set = train_set.shuffle(buffer_size=1000, seed=42, reshuffle_each_iteration=False) \\\n",
    "                     .batch(32, drop_remainder=True).prefetch(1)\n",
    "val_set = val_set.shuffle(buffer_size=1000, seed=42, reshuffle_each_iteration=False) \\\n",
    "                     .batch(32, drop_remainder=True).prefetch(1)\n",
    "test_set = test_set.shuffle(buffer_size=1000, seed=42, reshuffle_each_iteration=False) \\\n",
    "                     .batch(32, drop_remainder=True).prefetch(1)\n",
    "\n",
    "train_set = train_set.map(lambda x, y: (tf.expand_dims(x, 3), y))\n",
    "val_set = val_set.map(lambda x, y: (tf.expand_dims(x, 3), y))\n",
    "test_set = test_set.map(lambda x, y: (tf.expand_dims(x, 3), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_lookup = tf.concat([tf.constant([\"█\"]), tf.strings.bytes_split(tf.constant(chars))], axis=0)\n",
    "reverse_text = lambda x: tf.strings.join(tf.gather(char_lookup, tf.argmax(tf.concat([tf.fill([1, x.shape[1]], 0.5), x], axis=0), axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00040-97ba113e-2cb7-4e58-8d71-ba3685586921",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Now, we need to figure out how to initialize the patterns for the tokenization layer.<br>\n",
    "There's many ways to do it, however, a *good* pattern probably appears many times in the $text$, so here I'll intialize $patterns$ by getting all the n-grams (with \"n\" being the length of the pattern) in a corpus of text, then I rank the grams by how common it was in the corpus, and finally choose a gram randomly (with higher-ranking grams having a higher probability). When encoding these grams, we can't just one-hot encode it, as our $\\sigma (x)$ (shown in the section \"The Finer Details\") we use when updating the patterns will make it so that $0$s and $1$s basically *never* update. So, instead, we one-hot encode it and say that zeros are instead values coming from a normal distribution with $\\sigma = 0.25$ and $\\mu = 0.08$ (i.e. mean and standard deviation), and ones are insead values coming from a normal distribution with $\\sigma = 0.75$ and $\\mu = 0.08$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "00041-210ad1e2-2574-47ab-8755-0d353fe365d4",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 44,
    "execution_start": 1627764094704,
    "source_hash": "b1ad4342",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gram_count_batch(gram_len=10, filter_over=1):\n",
    "    gram_text = lambda x: tf.strings.ngrams(tf.strings.bytes_split(x), gram_len, separator=\"\")\n",
    "    def return_func(x):\n",
    "        grammed_batch = tf.ragged.map_flat_values(gram_text, x)\n",
    "        flattened_batch = grammed_batch.merge_dims(0, -1)\n",
    "        y, idx, count = tf.unique_with_counts(flattened_batch)\n",
    "        filter_ = tf.squeeze(tf.where(count > filter_over), 1)\n",
    "        filtered_y = tf.gather(y, filter_)\n",
    "        filtered_count = tf.gather(count, filter_)\n",
    "        return (filtered_y, filtered_count)\n",
    "    return return_func\n",
    "\n",
    "def one_hot_str(string):\n",
    "    return tf.transpose(tf.map_fn(lambda x: tf.cast(tf.constant(list(chars))==x, tf.int32), \n",
    "                        tf.strings.bytes_split(string), fn_output_signature=tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": "00042-d49391da-4ec1-4cf3-9ad6-eaedf692a0fd",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 63,
    "execution_start": 1627764094748,
    "source_hash": "a9fcda8b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data[\"review\"], data[\"sentiment\"], test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=42)\n",
    "X_train_data = tf.data.Dataset.from_tensor_slices(X_train)\n",
    "X_train_batched = X_train_data.batch(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "00043-5ab92fc2-1bfc-4f71-a5e8-01932b47a18c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1627764339087,
    "source_hash": "3b9eee6b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PatternsInitilizerMaxCover(keras.initializers.Initializer):\n",
    "    # Provide a list of possible pattern lengths (as `gram_lens`), when making a pattern it \n",
    "    # randomly chooses a length for that pattern (with uniform probability) from `gram_lens`.\n",
    "    def __init__(self, gram_lens, filter_over=1):\n",
    "        self.all_grams_dict, self.probs_dict = {}, {}\n",
    "        self.gram_lens = gram_lens\n",
    "        # Find the unique grams and their frequenicies for all gram_lens provided\n",
    "        for gram_len in self.gram_lens:\n",
    "            # Get all unique grams and their counts (in batches, because all at once eats the RAM)\n",
    "            X_train_batch_counted = X_train_batched.map(gram_count_batch(gram_len=gram_len, filter_over=filter_over))\n",
    "            gram_counts_batched = []\n",
    "            for batch in X_train_batch_counted:\n",
    "                gram_counts_batched.append(batch)\n",
    "            df = pd.DataFrame(gram_counts_batched)\n",
    "            # Concatenate batches together\n",
    "            all_counts = tf.concat(df[1].to_list(), axis=0)\n",
    "            all_grams = tf.concat(df[0].to_list(), axis=0)\n",
    "            # Normalize the counts to get the \"probabilites\"\n",
    "            probs = tf.expand_dims(all_counts / tf.reduce_sum(all_counts), 0)\n",
    "            # Save the unique grams and their proabilities\n",
    "            self.all_grams_dict[gram_len], self.probs_dict[gram_len] = all_grams, probs\n",
    "    \n",
    "    def __call__(self, shape, **kwargs):\n",
    "        patterns = []\n",
    "        # For every tokenization neuron:\n",
    "        for neuron in range(shape[3]):\n",
    "            # Choose a length for the pattern at random\n",
    "            pattern_len = np.random.choice(self.gram_lens)\n",
    "            # Choose a random gram of specified `pattern_len`\n",
    "            pattern = tf.gather(self.all_grams_dict[pattern_len], tf.random.categorical(tf.math.log(self.probs_dict[pattern_len]), 1))[0, 0]\n",
    "            # One-hot encode, pad, and save pattern\n",
    "            pattern_onehot = tf.cast(one_hot_str(pattern), tf.float32)\n",
    "            padding = tf.zeros((pattern_onehot.shape[0], max(self.gram_lens)-pattern_len))\n",
    "            patterns.append(tf.concat([pattern_onehot, padding], axis=1))\n",
    "        # Concatenate patterns to make final tensor\n",
    "        patterns = tf.expand_dims(tf.transpose(tf.stack(patterns), [1, 2, 0]), 2)\n",
    "        # Replace 0s and 1s with random values from differnet distributions respectively\n",
    "        return tf.where(patterns==0., tf.random.normal(patterns.shape, mean=0.25, stddev=0.08),\n",
    "                                      tf.random.normal(patterns.shape, mean=0.75, stddev=0.08))\n",
    "    def get_config(self):\n",
    "        return {\"gram_len\": gram_len, \"filter_over\": filter_over}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00044-4ecbbc4f-9609-4e0b-9ba5-96d129f0f657",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "As an example, here's some patterns this initialization makes (I made them only length 10 to save on compute):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": "00044-135fb3db-6555-40ce-8a68-d41d5603ec38",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 39843,
    "execution_start": 1627764727475,
    "is_code_hidden": true,
    "source_hash": "905985ab",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\marti\\anaconda3\\envs\\pythongeneral\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 100), dtype=string, numpy=\n",
       "array([[b'se people ', b' to the sc', b'll asleep ', b'lot elemen',\n",
       "        b' years old', b'e movie is', b'onstrated ', b'somewhere ',\n",
       "        b'ide from s', b'ey needed ', b'reenplay a', b' technique',\n",
       "        b'daptation ', b'me i think', b'roduction ', b'ast of the',\n",
       "        b' mini film', b'isnt anyth', b'tch the fi', b'e excellen',\n",
       "        b'his case i', b' it was hi', b'ing this m', b'ssible to ',\n",
       "        b'the photog', b'ose ends a', b'nd speakin', b'reality th',\n",
       "        b'r understa', b'acters tha', b'e kinds of', b'orking on ',\n",
       "        b'the script', b'n actor an', b'sterpiece ', b' brigante ',\n",
       "        b' dont unde', b'ason is be', b'cal christ', b'eaves with',\n",
       "        b'ound effec', b' humor tha', b'unusual th', b'in the ita',\n",
       "        b' of what i', b'ith the ma', b' scenes we', b't the rest',\n",
       "        b't see the ', b'ealistic t', b' several o', b'and someti',\n",
       "        b' to be one', b'at the ver', b'ing skills', b'worth watc',\n",
       "        b'tion to th', b'erspective', b'st movie t', b'there are ',\n",
       "        b't  anyway ', b'nce in the', b'e that she', b'ank accoun',\n",
       "        b'of the bes', b'way to the', b'ch makes t', b'r movies a',\n",
       "        b'ichael kea', b'ch has bee', b'nd the fac', b'n fbi agen',\n",
       "        b'eone who a', b'ck on trad', b' has all t', b'lieve this',\n",
       "        b' any movie', b'van damme ', b'hysterical', b'and compas',\n",
       "        b'back toget', b'e some kin', b'ng religio', b' the jewis',\n",
       "        b' does not ', b'clude the ', b'when you s', b'e it is al',\n",
       "        b'it is just', b'ount of ti', b'ie is grea', b'e girl who',\n",
       "        b' movie i h', b'onest with', b'especially', b'd because ',\n",
       "        b'd constant', b'yet anothe', b'rtaining i', b'oesnt take']],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram_len, filter_over = 10, 1\n",
    "X_train_batch_counted = X_train_batched.map(gram_count_batch(gram_len=gram_len, filter_over=filter_over))\n",
    "gram_counts_batched = []\n",
    "for batch in X_train_batch_counted:\n",
    "    gram_counts_batched.append(batch)\n",
    "df = pd.DataFrame(gram_counts_batched)\n",
    "all_counts = tf.concat(df[1].to_list(), axis=0)\n",
    "all_grams = tf.concat(df[0].to_list(), axis=0)\n",
    "probs = tf.expand_dims(all_counts / tf.reduce_sum(all_counts), 0)\n",
    "tf.gather(all_grams, tf.random.categorical(tf.math.log(probs), 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00053-c39724c1-807e-448a-910c-81a948acf103",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Then, let's define $\\sigma (x)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": "00053-a1073060-a58d-4a10-b7c3-32f996bc4e2d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7,
    "execution_start": 1627765084463,
    "source_hash": "90210989",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bump_func(x, a=-0.2, b=2.5):\n",
    "    a = -a/(-a+1)\n",
    "    x = (1-a)*x + a\n",
    "    return (x**(-b-1)) / ((1 + x**(-b) * (1 - x)**b)**2 * (-x + 1)**(-b+1))\n",
    "\n",
    "@tf.function\n",
    "def tokenization_transformation(x):\n",
    "    out_zeros = tf.where((x <= 0.) | (x >= 1.), 0., x)\n",
    "    out_smoothstep = tf.where((out_zeros > 0) & (out_zeros < 1), bump_func(out_zeros), out_zeros)\n",
    "    return out_smoothstep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00046-9523a902-581e-4c73-a400-f8b0b5d8a796",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Now, let's make the tokeniation layer itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": "00047-bee0a7b1-3738-48d7-bbeb-ddb17fe4f5b2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 21,
    "execution_start": 1627765086566,
    "source_hash": "c10b73ca",
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def tokenization(input_, patterns):\n",
    "    # `upstream` will have shape (batch_size, output_height/num_neurons, output_width/input_width, 1)\n",
    "    #     (you can imagine why output_height would be the same as num_neurons as \"the text is now \n",
    "    #      being represented by `num_neurons` neurons, and each neuron has it's one-hot encoding, \n",
    "    #      thus, height=num_neurons\". \n",
    "    #      We also specifically padded output_width to be the same as input_width in forward \n",
    "    #      propagation).\n",
    "    def grad(upstream):\n",
    "        # The first thing we need to do in backprop is make upstream to be as if it was\n",
    "        # made using just a convolution operation (in forward prop). So, we remove the padding\n",
    "        # we added in forward prop and transpose the dimensions a bit\n",
    "        amount_not_padding = tf.shape(upstream)[2] - tf.shape(patterns)[1] + 1\n",
    "        upstream = upstream[:, :, :amount_not_padding]\n",
    "        upstream = tf.transpose(upstream, [0, 3, 2, 1])\n",
    "        # Then, we need to get the gradients w.r.t. `input_` and `patterns`, pretending that forward\n",
    "        # prop was just a convolution of `patterns` on `input`.\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(input_)\n",
    "            tape.watch(patterns)\n",
    "            z = tf.nn.convolution(input_, patterns) * upstream # Note how we multiply (element-wise)\n",
    "            # with `upstream`!\n",
    "        grads = tape.gradient(z, [input_, patterns])\n",
    "        # Finally, we return the gradients (remembering to multiply the patterns' gradients \n",
    "        # element-wise with sigma(x)).\n",
    "        return grads[0], grads[1]*tokenization_transformation(patterns)\n",
    "    \n",
    "    # The `patterns` parameter is just arbritrary numbers. We want `patterns` to be able to match\n",
    "    # the text. For that each column must contain one \"1\" and the rest be zeros\n",
    "    # (one-hot encoding), to make that we take the maximum value in each column and say that's\n",
    "    # the \"1\". We would also like there to be columns that are ignored. Those columns would be\n",
    "    # filled with just zeros. To do that, we say that if the sum of all the values in a column\n",
    "    # is less than (or equal to) 0, that column if filled with just zero.\n",
    "    patterns_discrete = tf.cast(tf.math.logical_and(\n",
    "        patterns == tf.expand_dims(tf.reduce_max(patterns, axis=0), 0),\n",
    "        tf.reduce_sum(patterns, axis=0) > 0\n",
    "    ), tf.float32)\n",
    "    # Convolve the input with patterns_discrete\n",
    "    convolution = tf.nn.convolution(input_, patterns_discrete)\n",
    "    # Pad convolution to be the same length as `input_`\n",
    "    padding = tf.zeros([tf.shape(convolution)[0], tf.shape(convolution)[1], \n",
    "                        tf.shape(input_)[2]-tf.shape(convolution)[2], tf.shape(convolution)[3]])\n",
    "    convolution = tf.concat([convolution, padding], axis=2)\n",
    "    # Get the sums of all the different patterns respectively (this is so we\n",
    "    #  can find where in the text/s the pattern/s made a full match).\n",
    "    pattern_sums = tf.reduce_sum(patterns_discrete, axis=[0, 1])\n",
    "\n",
    "    # This function will take in one instance in the batch at a time\n",
    "    def transform_convolution(t):\n",
    "        return tf.transpose(tf.cast(tf.squeeze(t) == pattern_sums, tf.float32))\n",
    "    # Map `transform_convolution` over every instance in the batch\n",
    "    final = tf.map_fn(transform_convolution, convolution)\n",
    "    # Append an extra \"1\" in the shape (to be more like the input) and return\n",
    "    return tf.expand_dims(final, 3), grad\n",
    "\n",
    "class TokenizationLayer(keras.layers.Layer):\n",
    "    def __init__(self, n_neurons, possible_pattern_lens=[5, 6, 7, 8, 9, 10, 11, 12, 13], filter_over=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.n_neurons = n_neurons\n",
    "        self.possible_pattern_lens = possible_pattern_lens\n",
    "        self.filter_over = filter_over\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # Initialize parameters of TokenizationLayer\n",
    "        self.patterns = self.add_weight(\"patterns\", shape=[input_shape[1], max(self.possible_pattern_lens), 1, self.n_neurons],\n",
    "                                        initializer=PatternsInitilizerMaxCover(self.possible_pattern_lens, filter_over=self.filter_over))\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, input_):\n",
    "        return tokenization(input_, self.patterns)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tf.TensorShape(input_shape.as_list()[0]+[self.n_neurons]+input_shape.as_list()[2]+[1])\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"n_neurons\":self.n_neurons, \"possible_pattern_lens\":self.possible_pattern_lens,\n",
    "                \"filter_over\":self.filter_over}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00048-6b711246-583b-4cc7-a4db-94ef9732a9e8",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Okay, we have a tokenization layer! Now we just need to make the accompanying model.<br>\n",
    "In the model, we would like to use the `keras.layers.Embedding` layer to encode discrete values into vectors of (learnable) continuous values, however it only works as the *first* layer in a model, but we want the first layer to be the tokenization layer! So, I made a custom Embedding layer:<br> \n",
    "*for more on embeddings, I made a thing [here](http://legoboy7.pythonanywhere.com/nlp_embeddings). Note it's not too polished (I made it for myself).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": "00048-cf3db89f-4bb6-43a0-81eb-a0e0c004ccbe",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1627765088495,
    "source_hash": "44d3a859",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyEmbedding(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Takes in matrix of discrete values (one-hot encoded) and embeds them into \n",
    "    continuous values, trained like the rest of the network.\n",
    "    Shape of `X` should be `(batch_size, sequence_length, onehot_categories)`\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_length, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embedding_length = embedding_length\n",
    "    \n",
    "    # input_shape = (batch_size, sequence_length, num_unique_vals)\n",
    "    def build(self, input_shape):\n",
    "        self.embedding_matrix = self.add_weight(name=\"embedding_matrix\", \n",
    "                                                shape=[input_shape[2], self.embedding_length],\n",
    "                                                initializer=\"glorot_uniform\")\n",
    "        super().build(input_shape)\n",
    "    \n",
    "    def call(self, X):\n",
    "        return tf.matmul(X, self.embedding_matrix)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tf.TensorShape(input_shape.as_list()[:-1] + [self.embedding_length])\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"embedding_length\": self.embedding_length}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00050-f15229d9-77c0-4623-a87c-a75fffedda33",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Now for the model itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": "00050-2e8aa691-aa75-4213-8d45-9f7080f48709",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 15,
    "execution_start": 1627765091188,
    "source_hash": "21d66dba",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelTokenization(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(ModelTokenization, self).__init__(name='')\n",
    "        \n",
    "        self.tokenization = TokenizationLayer(n_neurons=500)\n",
    "        self.lambda1 = keras.layers.Lambda(lambda x: tf.transpose(tf.squeeze(x, 3), [0, 2, 1]))\n",
    "        self.embedding = MyEmbedding(1)\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "\n",
    "        self.batch_norm1 = keras.layers.BatchNormalization()\n",
    "        self.dense = keras.layers.Dense(64)\n",
    "        self.out = keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, input_tensor, return_intermediates=False, training=False):\n",
    "        tokenization_out = self.tokenization(input_tensor, training=training)\n",
    "        lambda1_out = self.lambda1(tokenization_out, training=training)\n",
    "        embedding_out = self.embedding(lambda1_out, training=training)\n",
    "        flatten_out = self.flatten(embedding_out)\n",
    "\n",
    "        batch_norm1_out = self.batch_norm1(flatten_out, training=training)\n",
    "        dense_out = self.dense(batch_norm1_out, training=training)\n",
    "        out = self.out(dense_out, training=training)\n",
    "\n",
    "        if return_intermediates:\n",
    "            return out, dense_out, flatten_out, embedding_out, lambda1_out, tokenization_out\n",
    "        else:\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": "00052-f311b14c-d90f-4410-8889-3d44e09fd0d0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 52685,
    "execution_start": 1626461029761,
    "source_hash": "1443f24c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_tokenization\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "tokenization_layer (Tokeniza multiple                  195000    \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_embedding (MyEmbedding)   multiple                  500       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  8000      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  128064    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  65        \n",
      "=================================================================\n",
      "Total params: 331,629\n",
      "Trainable params: 327,629\n",
      "Non-trainable params: 4,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ModelTokenization()\n",
    "_ = model(tf.zeros([32, 30, 2000, 1]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00062-93966e95-5006-47ad-8173-e10c9304a234",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Finally, let's make the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": "00063-8444d687-b0da-47a2-87b5-4d5e536d0da4",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam()\n",
    "loss_fn = keras.losses.BinaryCrossentropy()\n",
    "train_acc_metric = keras.metrics.Accuracy()\n",
    "val_acc_metric = keras.metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": "00065-4bddcd88-0e38-4b11-8560-fa351cf4f7b4",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"model_checkpoints/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": "00064-08095b3a-790f-4b4b-8bb5-2f8ed672f5bd",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(path+\"patterns_log.txt\", \"a+\") as f:\n",
    "    pass\n",
    "with open(path+\"grads_log.csv\", \"a+\") as f:\n",
    "    f.write(\"Out Mean,Out Std,Dense Mean,Dense Std,Embedding Mean,Embedding Std,Tokenization Mean,\"+\\\n",
    "            \"Tokenization Std,Out Kernel Mean,Out Kernel Std,Out Bias Mean,Out Bias Std,\"+\\\n",
    "            \"Dense Kernel Mean,Dense Kernel Std,Dense Bias Mean,Dense Bias Std,\"+\\\n",
    "            \"Embedding Kernel Mean,Embedding Kernel Std,Patterns Mean,Patterns Std,\\n\")\n",
    "with open(path+\"vals_log.csv\", \"a+\") as f:\n",
    "    f.write(\"Out Mean,Out Std,Dense Mean,Dense Std,Embedding Mean,Embedding Std,Tokenization Mean,\"+\\\n",
    "            \"Tokenization Std,Out Kernel Mean,Out Kernel Std,Out Bias Mean,Out Bias Std,\"+\\\n",
    "            \"Dense Kernel Mean,Dense Kernel Std,Dense Bias Mean,Dense Bias Std,\"+\\\n",
    "            \"Embedding Kernel Mean,Embedding Kernel Std,Patterns Mean,Patterns Std,\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00065-060dfbba-60cf-439a-a836-cf94063ed1db",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    train_loss_rounded, train_acc_rounded = 0, 0\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_set):\n",
    "        # -=-= COMPUTE GRADIENTS OF BATCH  =-=-\n",
    "        with tf.GradientTape() as tape:\n",
    "            z, dense_out, flatten_out, embedding_out, lambda1_out, tokenization_out = model(x_batch_train, return_intermediates=True, training=True)\n",
    "            z = tf.squeeze(z, 1)\n",
    "            loss = loss_fn(y_batch_train, z)\n",
    "        layer_vals = [z, dense_out, embedding_out, tokenization_out]\n",
    "        grads = tape.gradient(loss, layer_vals+model.trainable_variables)\n",
    "        layer_grads = grads[:len(layer_vals)]\n",
    "        grads = grads[len(layer_vals):]\n",
    "        \n",
    "        # -=-= LOG INGO  =-=-\n",
    "        progress_bar_done = \"\".join([\"█\" for _ in range(round( step*20/len(train_set) ))])\n",
    "        progress_bar_left = \"\".join([\" \" for _ in range(20-round( step*20/len(train_set) ))])\n",
    "        percent_done = round(step*100/len(train_set), 2)\n",
    "\n",
    "        save_patterns = False\n",
    "        if step%10 == 0:\n",
    "            save_patterns = True\n",
    "            # Decode patterns\n",
    "            patterns = model.tokenization.patterns\n",
    "            patterns = tf.cast(tf.math.logical_and(\n",
    "                patterns == tf.expand_dims(tf.reduce_max(patterns, axis=0), 0),\n",
    "                tf.reduce_sum(patterns, axis=0) > 0\n",
    "            ), tf.float32)\n",
    "            patterns_decoded = [reverse_text(pattern).numpy().decode() for pattern in tf.transpose(tf.squeeze(patterns, 2), [2, 0, 1])]\n",
    "            # Get patterns to log\n",
    "            pattern_grads = tf.transpose(tf.squeeze(grads[0], 2), [2, 0, 1])\n",
    "            pattern_grads_summary = tf.math.reduce_std(pattern_grads, axis=[1, 2])+tf.abs(tf.reduce_mean(pattern_grads, axis=[1, 2]))\n",
    "            pattern_grads_sorted_indexes = list(pd.Series(pattern_grads_summary).sort_values().keys())\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(f'Epoch {epoch+1}/{epochs} - |{progress_bar_done}{progress_bar_left}| - {percent_done}% - {step+1}/{len(train_set)}')\n",
    "        print(f'Train loss: {train_loss_rounded} - Train accuracy: {train_acc_rounded}')\n",
    "        print()\n",
    "        # Log patterns\n",
    "        top_n = 15\n",
    "        buffer = \"\".join(\"0\" for _ in range(7))\n",
    "\n",
    "        patterns_log_high = [f'\"{patterns_decoded[i]}\": '+(str(pattern_grads_summary[i].numpy()*100)+buffer)[:7]+\" | \" \n",
    "                             for i in pattern_grads_sorted_indexes[-top_n:]]\n",
    "        num_per_row = int(np.floor(135/len(patterns_log_high[0])))\n",
    "        print(f\"{color.BOLD}Patterns with diverse non-zero gradients{color.END}\")\n",
    "        for i in range(int(np.floor(len(patterns_log_high)/num_per_row))):\n",
    "            print(\"\".join(patterns_log_high[(i)*num_per_row:(i+1)*num_per_row]))\n",
    "        if len(patterns_log_high)%num_per_row != 0:\n",
    "            print(\"\".join(patterns_log_high[-(int(np.floor(len(patterns_log_high)/num_per_row))*num_per_row)+1:]))\n",
    "\n",
    "        patterns_log_low = [f'\"{patterns_decoded[i]}\": '+(str(pattern_grads_summary[i].numpy()*100)+buffer)[:7]+\" | \" \n",
    "                             for i in pattern_grads_sorted_indexes[:top_n]]\n",
    "        num_per_row = int(np.floor(135/len(patterns_log_low[0])))\n",
    "        print(f\"{color.BOLD}Patterns with mostly zero gradients{color.END}\")\n",
    "        for i in range(int(np.floor(len(patterns_log_low)/num_per_row))):\n",
    "            print(\"\".join(patterns_log_low[(i)*num_per_row:(i+1)*num_per_row]))\n",
    "        if len(patterns_log_low)%num_per_row != 0:\n",
    "            print(\"\".join(patterns_log_low[-(int(np.floor(len(patterns_log_low)/num_per_row))*num_per_row)+1:]))\n",
    "\n",
    "        # -=-= UPDATE NETWORK & METRICS  =-=-\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        train_acc_metric.update_state(y_batch_train, tf.round(z))\n",
    "        train_loss_rounded, train_acc_rounded = \"%.4f\" % loss.numpy(), \"%.4f\" % train_acc_metric.result().numpy()\n",
    "\n",
    "        # -=-= SAVE THINGS TO DRIVE  =-=-\n",
    "        if (step%int(np.floor(len(train_set)/5))==0) and (step != 0):\n",
    "            cp_num = len(os.listdir(path))-1\n",
    "            model_cp = tf.train.Checkpoint(model=model)\n",
    "            model_cp.write(path+f\"model_cp_{cp_num}/model_checkpoint\")\n",
    "        if save_patterns:\n",
    "            with open(path+\"patterns_log.txt\", \"a+\") as f:\n",
    "                [f.write(f'\"{pattern}\", ') for pattern in patterns_decoded]\n",
    "                f.write(\"\\n\")\n",
    "        with open(path+\"grads_log.csv\", \"a+\") as f:\n",
    "            for layer_index in [0, 1, 2, 3]:\n",
    "                f.write(str( tf.reduce_mean(layer_grads[layer_index]).numpy() )+\",\")\n",
    "                f.write(str( tf.math.reduce_std(tf.reduce_mean(layer_grads[layer_index], axis=0)).numpy() )+\",\")\n",
    "            for param_index in [6, 7, 4, 5, 1, 0]:\n",
    "                f.write(str( tf.reduce_mean(grads[param_index]).numpy() )+\",\")\n",
    "                f.write(str( tf.math.reduce_std(grads[param_index]).numpy() )+\",\")\n",
    "            f.write(\"\\n\")\n",
    "        with open(path+\"vals_log.csv\", \"a+\") as f:\n",
    "            for layer_index in [0, 1, 2, 3]:\n",
    "                f.write(str( tf.reduce_mean(layer_vals[layer_index]).numpy() )+\",\")\n",
    "                f.write(str( tf.math.reduce_std(tf.reduce_mean(layer_vals[layer_index], axis=0)).numpy() )+\",\")\n",
    "            for param_index in [6, 7, 4, 5, 1, 0]:\n",
    "                f.write(str( tf.reduce_mean(model.trainable_variables[param_index]).numpy() )+\",\")\n",
    "                f.write(str( tf.math.reduce_std(model.trainable_variables[param_index]).numpy() )+\",\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    train_acc_metric.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00070-783fa18e-636b-4dc2-9e39-6ac93416e4a4",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Okay! With this we can now train a model using the tokenization layer (I haven't done it here as it *is* pretty expensive, computationally). However..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00068-2650c9d0-57e3-42fa-9bb1-b85344d1d0f3",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Wait... But *will* it Work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00053-7de97ee0-26be-407a-a0ad-0936d608ca03",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Alright, this is all well and good, but can it actually train? Will it be able to make the right ajustments to the patterns, and will it not get stuck in a bad local minimum? Well, here's how we get the gradients of the patterns:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00054-04cd2363-e465-47ab-b218-662e0a2259cd",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "$$\n",
    "\\frac{\\partial C}{\\partial pattern} = text * upstream\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00055-68c78b5e-42af-4e6e-a9e6-465916d0cff3",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "One worry about this is that the $text$ (and subsequently the $upstream$ because the patterns are going to be comparably small) will be be very big (like `30x2000`). That means that in the convolution between these two (above), each value is going to be the weighted sum of thousands of values. If the distribution of upstream isn't 0, those thousands will add up, and the gradients will become huge. So, we have to be careful that the upstream gradient has a mean of $0$.<br>\n",
    "Luckily in that regard, our embedding layer that comes just after the tokenization layer (where our worries here lie) can act as a sort-of normilization, so it should be fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00056-2fd246b8-4fcc-4bfa-821a-7791fbc71eec",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Other than that (which I also have in StackOverflow [here](https://math.stackexchange.com/questions/4190012/backpropagating-convolution-with-big-image-to-train-comparably-small-filter/4190918#4190918) btw), it really is just a regular convolution, so it should be able to make the right ajustments. However, what if the very nature of this task means that it'll just get stuck in a local minima right away? To get closer to the answer, we need some intuition for how the patterns *actually* update:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00057-f7b2f733-3af3-4c23-a2e2-49ed8c687cf4",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "In forward prop, we start with the patterns, which are applied to the input text, with matches then being embedded in an embedding layer and used by the rest of the network, in mysterious ways, to make a prediction.<br>\n",
    "In backprop we start with the (mysterious) final output of the network, and see what we should do to minimize the margin of error from the real value (e.g. for predicting movie review sentiments, we predict 0.4, when in truth it was 1, and so we should *increase* the value 0.4, so that it's closer to 1). Then, we distribute this \"what-to-do\" to the output of the layer before, asking how we should change these values to minimize error. It's like saying \"Okay, so to minimize error we should change this layer's output like this, and to do that we should change the previous layer's output like that\" and so on.<br>\n",
    "Eventually, we get back to the output of the tokenization layer, where we now know how to change each of the output values in order to minimize the error. From this we can update the patterns, which all have the way in which to change their output of them on the input text respectively. Using this and the input text itself, it updates the patterns.<br>\n",
    "That means, the patterns change so that the way in which the rest of the network uses said patterns to make predictions is \"less wrong\". It's trying to change the patterns so that the output of the tokenization layer follows the \"what-to-do\" to minimize error (illustrated in the example below).<br>\n",
    "So really, it depends on how the network is using the token *now*, and how that part of the network would like to see the token to appear elsewhere in the text (thus changing it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00072-049aff5c-e381-47a5-870b-bb101c8fad1a",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00058-34516f5f-0351-42e1-85ff-cd195db05093",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "For example, if we have following input text and pattern:\n",
    "$$\n",
    "\\text{text} = \\begin{bmatrix}\n",
    "1&0&0&1&0&0&0&1&0 \\\\\n",
    "0&0&1&0&0&0&0&0&1 \\\\\n",
    "0&0&0&0&0&0&1&0&0 \\\\\n",
    "0&0&0&0&1&0&0&0&0 \\\\\n",
    "0&1&0&0&0&1&0&0&0\n",
    "\\end{bmatrix}, \\text{ pattern} = \\begin{bmatrix}\n",
    "0 & 1 & 1 \\\\\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "0 & 0 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Then this would be the resulting convolution of the two (which as we know is the \"sort-of\" forward prop):\n",
    "\n",
    "$$\n",
    "\\text{text} * \\text{pattern} = \\begin{bmatrix}\n",
    "0 & 1 & 2 & 0 & 0 & 1 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "Now, let's say that in backprop, it finds that for the rest of the network to have less error, here is how the tokenization layer's output should change (i.e. the gradient of cost w.r.t. the tokenization layer's output):\n",
    "\n",
    "$$\n",
    "\\text{upstream} = \\begin{bmatrix}-0.1 & -0.5 & 0.9 & 0.0 & 0.0 & -0.2 & -0.1 \\end{bmatrix}\n",
    "$$\n",
    "Now, with this we can find how to change $\\text{pattern}$ in order to minimize error (i.e. $\\partial C / \\partial \\text{pattern}$):\n",
    "\n",
    "$$\n",
    "\\text{text} * \\text{upstream} = \\begin{bmatrix}\n",
    "-0.1 & 0.8  & -0.7 \\\\\n",
    "0.9  & -0.5 & -0.2 \\\\\n",
    "-0.1 & -0.2 & 0.0  \\\\\n",
    "0.0  & 0.0  & 0.9  \\\\\n",
    "-0.7 & -0.1 & 0.0  \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "You can see how this would be trying to change $\\text{pattern}$ to be more like the pattern below, which makes sense, because in forward prop the pattern below gets a full match where there's a $0.9$ in $\\text{upstream}$.\n",
    "$$\n",
    "\\text{text} * \\begin{bmatrix}\n",
    "0 & 1 & 0 \\\\\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "0 & 0 & 1 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "\\end{bmatrix} = \\begin{bmatrix} 0 & 0 & 3 & 0 & 0 & 0 & 1 \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00074-710dd1a7-7bd5-4e63-9398-3cdcd647f2b6",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00075-18cd22e0-2292-441b-96bc-ac6265a018d7",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Here then, is the (sad) conclusion to if it'll be able to train:<br>\n",
    "It is very hard for a token to output anything. Most possible tokens will never appear in a text, and changing even one letter of a token that *does* work can completely ruin it.<br>\n",
    "When the network encounters useless tokens, it simply continues trying to find how to utilize this output to make \"less wrong\" predictions. Eventually it'll converge, and if it does that while the token is *still* useless, the token will start *wanting* to be useless, as that's how network likes it best now. In other words, it gets stuck in a local minima where the token is useless (I've shown this to be the case [here](https://deepnote.com/project/Testing-Uk3lFFe2RcaFLNgo2L1v5w/%2Fmanual-networks.ipynb/)).<br>\n",
    "So, if the token is useless for too long, it'll never recover, but what's to say that a token *will* be useless? Well, while you could use custom initialization strategies to make tokens that *do* appear in the text (as we've done here), when the network will try to change them, they will become useless (all it takes is one letter) while the network tries to make the tokens it *actually* wants. Here also lies the final problem; tokens the network *actually* wants are probably impossible to get... <br>\n",
    "To the network, a token is defined by where it appears in the text, and this is what it's trying to change when it's changing tokens. However, most possible outputs are in fact *impossible* when in practice; there's no possible token that can produce said output.\n",
    "\n",
    "So, as the tokens try to become impossible versions of themselves, they instead become useless tokens, that'll never appear in any text. The rest of the network then *get's used* to the tokens being useless, and get's stuck in a local minima. ***The End.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00079-7462a80d-6b16-4bc7-a1fe-576a4b7199fa",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "I have tried to train it (using the code above), and this is indeed what happens. So..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00080-22398924-f24c-4c4b-8eb7-5001b923f07e",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00081-7c01d46a-6745-4ee0-a1b9-59fe397a5e33",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "In this notebook we came up with the \"tokenization layer\", which is a tokenization algorithm trainable by gradient descent, and is meant to be the first layer in a deep learning model, learning the tokens best for the specific model for the specific task.<br>\n",
    "However, in the end, we couldn't get it to work due to the nature of tokens in general.\n",
    "\n",
    "Here's a couple last-minute things I came up with you could do to try fix this:\n",
    "\n",
    "* Freeze patterns shown in forward propagation to the last pattern that isn't \"useless\" (i.e. never shows up in any text)\n",
    "* Somehow \"approximate\" the upstream gradient at the tokenization layer to be something \"possible\" by a pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00084-2d1ffa52-233c-46f8-84bb-fe77fb02d7c1",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# The End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00066-182a3c72-3c93-4787-b350-c630b421ac63",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00084-c16d3b27-530e-4fbb-bcf1-85f31e87d297",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "*showing how it handles upstream gradients that are impossible for it to do*\n",
    "\n",
    "$$\n",
    "\\text{text} = \\begin{bmatrix}\n",
    "1&0&0&1&0&0&0&1&0 \\\\\n",
    "0&0&1&0&0&0&0&0&1 \\\\\n",
    "0&0&0&0&0&0&1&0&0 \\\\\n",
    "0&0&0&0&1&0&0&0&0 \\\\\n",
    "0&1&0&0&0&1&0&0&0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{upstream} = \\begin{bmatrix}\n",
    "0.5 & 0.4 & -0.7 & 0. & -0.1 & 0.2 & -0.3\n",
    " \\end{bmatrix}\n",
    "$$\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\text{text} * \\text{upstream} = \\begin{bmatrix}\n",
    "0.5 & -1.0 & 0.6 \\\\\n",
    "-0.7 & 0.4 & 0.2 \\\\\n",
    "-0.3 & 0.2 & -0.1 \\\\\n",
    "-0.1 & 0.0 & -0.7 \\\\\n",
    "0.6 & 0.4 & 0.0 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "*it tries to make*\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 0 & 1 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "\\end{bmatrix} \\text{and} \\begin{bmatrix}\n",
    "0 & 0 & 1 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "1 & 0 & 0 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "*of course, it's only possible for it to be one or the other, and having them both together is nonsensical.*"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "a2442cfe-8734-4e21-9377-6ebfa404ec48",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
